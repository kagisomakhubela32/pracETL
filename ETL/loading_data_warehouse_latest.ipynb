{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d00f20-81c3-4993-bade-2cae049f67e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import psycopg2\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import re\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4164f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up logs\n",
    "logging.basicConfig(\n",
    "    filename='etl_data_warehouse_logs.txt', \n",
    "    level=logging.INFO,      \n",
    "    format='%(asctime)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff89c5bc-d70c-4609-8889-ab7c48b07a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables for connection parameters for staging area\n",
    "username = 'postgres'\n",
    "password = 'makhubela'\n",
    "host = 'localhost'\n",
    "port = '5432'\n",
    "database = 'DW_staging_area'\n",
    "\n",
    "# Construct the connection string using variables\n",
    "connection_string_staging = f'postgresql://{username}:{password}@{host}:{port}/{database}'\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine_staging = create_engine(connection_string_staging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c40174-0024-45f1-bf6c-658f3045072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables for connection parameters for data warehouse\n",
    "username = 'postgres'\n",
    "password = 'makhubela'\n",
    "host = 'localhost'\n",
    "port = '5432'\n",
    "database = 'data_warehouse'\n",
    "\n",
    "# Construct the connection string using variables\n",
    "connection_string_DW = f'postgresql://{username}:{password}@{host}:{port}/{database}'\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine_DW = create_engine(connection_string_DW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a1258-427c-4cf5-8254-9ea29fe32fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty dictonery for the DataFrames\n",
    "total_num_row = 0\n",
    "\n",
    "table_data = {}\n",
    "\n",
    "table_names = ['city',\n",
    "               'country',\n",
    "               'province',\n",
    "               'day_part',\n",
    "               'day_date',\n",
    "               'franchisee',\n",
    "               'product_category',\n",
    "               'stores',\n",
    "               'product_group_level1',\n",
    "               'product_group_level2',\n",
    "               'product_group_level3',\n",
    "               'product_group_level4',\n",
    "               'sales_type',\n",
    "               'trading_hours',\n",
    "               'volumn_band',\n",
    "               'owner_operator',\n",
    "               'order_type',\n",
    "               'daily_sales_products',\n",
    "               'dw_batch']\n",
    "try:\n",
    "    for table in table_names:\n",
    "        query = f\"SELECT * FROM {table}\"\n",
    "        table_data[table] = pd.read_sql(query,con=engine_staging)\n",
    "        logging.info(f\"Number of rows in {table} : {len(table_data[table])}\")\n",
    "        print(f\"Number of rows in {table} : {len(table_data[table])}\")\n",
    "        number_row = len(table_data[table])\n",
    "        total_num_row = number_row + total_num_row\n",
    "except Exception as e:\n",
    "    logging.warning(\"error occured: error loading tables as dataframes\", exc_info=True) \n",
    "print(\"the total number of all rows = \",total_num_row)\n",
    "logging.info(f\"the total number of all rows = ,{total_num_row}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafe2960-e199-4557-84bb-31e6461a2ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data into dataframes \n",
    "try:\n",
    "    df_city = table_data['city']\n",
    "    df_country = table_data['country']\n",
    "    df_province = table_data['province']\n",
    "    df_day_part = table_data['day_part']\n",
    "    df_day_date = table_data['day_date']\n",
    "    df_franchisee = table_data['franchisee']\n",
    "    df_product_category = table_data['product_category']\n",
    "    df_stores = table_data['stores']\n",
    "    df_product_group_level1 = table_data['product_group_level1']\n",
    "    df_product_group_level2 = table_data['product_group_level2']\n",
    "    df_product_group_level3 = table_data['product_group_level3']\n",
    "    df_product_group_level4 = table_data['product_group_level4']\n",
    "    df_sales_type = table_data['sales_type']\n",
    "    df_trading_hours = table_data['trading_hours']\n",
    "    df_volumn_band = table_data['volumn_band']\n",
    "    df_owner_operator = table_data['owner_operator']\n",
    "    df_order_type = table_data['order_type']\n",
    "    df_daily_sales_products = table_data['daily_sales_products']\n",
    "    df_dw_batch = table_data['dw_batch']\n",
    "    logging.info(\"loading tables as dataframes successul!\")\n",
    "except Exception as e:\n",
    "    logging.warning(\"error occured: error loading tables as dataframes\", exc_info=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7c1e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list of dataframes \n",
    "total_num_row = 0\n",
    "data_frames = [df_city,\n",
    "               df_country,\n",
    "               df_province,\n",
    "               df_day_date,\n",
    "               df_day_part,\n",
    "               df_franchisee,\n",
    "               df_product_category,\n",
    "               df_stores,\n",
    "               df_product_group_level1,\n",
    "               df_product_group_level2,\n",
    "               df_product_group_level3,\n",
    "               df_product_group_level4,\n",
    "               df_sales_type,\n",
    "               df_trading_hours,\n",
    "               df_volumn_band,\n",
    "               df_owner_operator,\n",
    "               df_order_type,\n",
    "               df_daily_sales_products]\n",
    "\n",
    "#deleting unwanted columns in all tables namely [sbID and dwbID]\n",
    "try:\n",
    "    for table in data_frames:\n",
    "        table.drop(['sbID','dwbID'],axis=1,inplace=True)\n",
    "    logging.info(\"dropping columns: sbID and/or dwbID successful!\")    \n",
    "except Exception as e:\n",
    "    logging.warning(\"error occured: error dropping columns: sbID and/or dwbID \", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eba172-17e3-4959-9a39-16c9efc84dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranformations\n",
    "#joining 2 dataframes in to 1\n",
    "try:\n",
    "    df_merge = pd.merge(df_city,df_province, on ='ProvinceID', how='inner')\n",
    "    df_concat = pd.concat([df_merge,df_country],axis=1)\n",
    "    logging.info('merging city,province and country tables successful!')\n",
    "except Exception as e:\n",
    "    logging.warning(\"error occured: error merging city,province and country tables\", exc_info=True) \n",
    "#creating location table\n",
    "try:\n",
    "    df_concat['CountryName'] = df_concat['CountryName'].fillna(df_country['CountryName'].iloc[0] )\n",
    "    df_location = df_concat.loc[:,['CityID','CityName','CountryName','ProvinceName']]\n",
    "except Exception as e:\n",
    "    logging.warning(\"error occured: error creating location table\", exc_info=True)     \n",
    "#renaming the column\n",
    "df_location = df_location.rename(columns = {'CityID':'LocationID'})\n",
    "\n",
    "#filling Location ID on fact table\n",
    "try:\n",
    "    df_daily_sales_products['LocationID'] = df_daily_sales_products['CityID']\n",
    "    logging.info(\"LocationID column successfully create\")\n",
    "except Exception as e:\n",
    "    logging.warning(\"error occured: error creating LocationID in the daily_sales_products fact table\", exc_info=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fcf3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming columns \n",
    "try:\n",
    "    df_stores = df_stores.rename(columns = {'McDelivery': 'Deliveries','McCafe' : 'Cafe'})\n",
    "    df_daily_sales_products = df_daily_sales_products.rename(columns = {'McDelivery': 'Deliveries','McCafe' : 'Cafe'})\n",
    "    logging.info(\"Renamed columns McDelivery and McCafe for the stores table,and daily_sales_products \")\n",
    "except Exception as e:\n",
    "    logging.warning(\"error occured: error Renaming columns McDelivery and McCafe for the stores table,and daily_sales_products\", exc_info=True)\n",
    "    \n",
    "#replacing mc,mcD and Mcdonald's from emails\n",
    "dict_owner_emails = { 'macdonalds':'restuarant',\n",
    "                     'mcd':'rs',\n",
    "                     'mc':'rs'\n",
    "                    }\n",
    "\n",
    "original_email = df_owner_operator['EmailAddress']\n",
    "\n",
    "def replace_trademarks_1(value):\n",
    "    if value is not None:  # Check if value is not None\n",
    "        for original, replacement in dict_owner_emails.items():\n",
    "            value = value.replace(original, replacement)\n",
    "    return value\n",
    "try:\n",
    "# Apply the custom function to the 'EmailAddress' column\n",
    "    df_owner_operator['EmailAddress'] = df_owner_operator['EmailAddress'].apply(replace_trademarks_1)\n",
    "    logging.info(\"changing emails to not reference McDonald's successful\")\n",
    "except Exception as e:\n",
    "    logging.warning(\"error occured: error changing emails to not reference McDonald's \", exc_info=True)\n",
    "new_email = df_owner_operator['EmailAddress']\n",
    "# Count the number of rows that changed\n",
    "try:\n",
    "    changed_rows_emails = (original_email != new_email).sum()\n",
    "    print(f\" number of changed rows {changed_rows_emails}\")\n",
    "    logging.info(f\" number of changed rows {changed_rows_emails}\")\n",
    "except Exception as e:\n",
    "    logging.warning(\"error occured: error in number of changed rows for owner operator email column\", exc_info=True)\n",
    "try:\n",
    "    original_franchisee = df_franchisee['FranchiseeName']\n",
    "    # Replace 'FranchiseeName' column\n",
    "    df_franchisee['FranchiseeName'] = df_franchisee['FranchiseeName'].str.replace('Mc','')\n",
    "    #new franchisee variable after changes \n",
    "    new_franchisee_name = df_franchisee['FranchiseeName']\n",
    "    # Count the number of rows that changed\n",
    "    changed_rows_franchisee_names = (original_franchisee != new_franchisee_name).sum()\n",
    "    print(f\" number of changed rows {changed_rows_franchisee_names}\")\n",
    "    logging.info(f\" number of changed rows {changed_rows_franchisee_names} in franchisee table\")\n",
    "except Exception as e:\n",
    "    logging.warning(\"error occured: error in changing franchisee table, FranchiseeName column\", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8397dc14-62f0-4c46-bcdb-5b91f20a13d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "orginal_product_desc = df_product_group_level4['ProductLevel4Desc']\n",
    "\n",
    "dict_trademarks = { 'McFlurry' : 'Ice Cream' ,\n",
    "                   'Mcflurry' : 'Ice Cream',\n",
    "                   'Delux' : 'Burger',\n",
    "                   'Deluxe' : 'Burger',\n",
    "                   'BigMacDev' : 'Tower Burger',\n",
    "                   'Mac' : 'Specialty Burger',\n",
    "                   'Boerie' : 'Boerivoers',\n",
    "                   'Foldover' :'Sandwich',\n",
    "                   'Big Mac' :'Big Burger',\n",
    "                    'Grand' : 'Gigalicous',\n",
    "                   'Junior' : 'Kiddie',\n",
    "                   'Quarter' :'Single Patty',\n",
    "                   'Qtr' : 'Single Patty',\n",
    "                    'McMuffin' : 'English Muffin',\n",
    "                   'Fillet-O-Fish': 'Fish Block',\n",
    "                   'bigtasty' : 'Sizeable Delight',\n",
    "                    'Big Tasty' :' Sizeable Delight',\n",
    "                   'Mcfeast' : 'Banquet',\n",
    "                   'McFeast' : 'Banquet',\n",
    "                   'Mcchicken' : 'Chicken Burger',\n",
    "                    'McChicken' : 'Chicken Burger',\n",
    "                   'Upsize' : 'Enlarge',\n",
    "                   'QP' : 'Single Patty',\n",
    "                    'Grand Big MAC' : 'Gigalicous Big Burger',\n",
    "                   'BOGOF' : 'Drama Burger',\n",
    "                   'Sharebag' : 'Share Meal',\n",
    "                    'sharebag' : 'Share Meal',\n",
    "                   'Share Box' : 'Family Pack',\n",
    "                   'ShareBox' : 'Family Pack',\n",
    "                    'Jr. MAC' : 'Regular Burger',\n",
    "                   'Happy' : 'Joyful',\n",
    "                   'McFizz' : 'Soda Float',\n",
    "                    'QPC' : 'Single Patty Cheese',\n",
    "                   'Grand Chicken' : 'Gigalicous Chicken',\n",
    "                    'Green Apple Fizz' : 'Green Apple Soda',\n",
    "                   'Koko Donut' : 'Chocolate Donut',\n",
    "                    'Bigtasty' : 'Mega Burger',\n",
    "                   'McBites' : 'Fried Chicken Snacks',\n",
    "                   'Mac Jr' :'Regular Burger',  \n",
    "                    'Mc Wings' : 'Chicken Wings',\n",
    "                   'McBraai' : 'Braai', \n",
    "                   'McDouble' : 'Double Patty Burger',  \n",
    "                    'McMixa' : 'Decadent Ice Cream', \n",
    "                   'Mcdipper' : 'Cheese Sticks', \n",
    "                   'McRoyale' : 'Cheesy Burger' \n",
    "                    }\n",
    "#replacing function for Mcdonald's trademarks\n",
    "def replace_trademarks_2(value):\n",
    "    for original, replacement in dict_trademarks.items():\n",
    "        value = value.replace(original, replacement)\n",
    "    return value\n",
    "try:\n",
    "    # Apply the custom function to the 'ProductLevel4Desc' column\n",
    "    df_product_group_level4['ProductLevel4Desc'] = df_product_group_level4['ProductLevel4Desc'].apply(replace_trademarks_2)\n",
    "    new_product_desc = df_product_group_level4['ProductLevel4Desc']\n",
    "    # Count the number of rows that changed\n",
    "    changed_rows_desc = (orginal_product_desc != new_product_desc).sum()\n",
    "    print(f\" number of changed rows {changed_rows_desc}\")\n",
    "    logging.info(f\" number of changed rows {changed_rows_desc} in ProductGroupLevel4 table,ProductLevel4Desc column. removed macdonald's references\")\n",
    "except Exception as e:\n",
    "    logging.warning(\"error occured: error in changing ProductGroupLevel4 table, ProductLevel4Desc column. could not remove macdonald's references\", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04131fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def is_valid_email(email):\n",
    "    pattern = r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'\n",
    "    return re.match(pattern, email) is not None\n",
    "\n",
    "# Function to clean the emails\n",
    "def clean_email(email):\n",
    "    if is_valid_email(email):\n",
    "        return email\n",
    "    else:\n",
    "        return None\n",
    "try:    \n",
    "    original_emails = df_stores['EmailAddress']\n",
    "    cleaned_emails = original_emails.apply(clean_email)\n",
    "    # Count the number of rows that changed\n",
    "    changed_rows_email = (original_emails != cleaned_emails).sum()\n",
    "    logging.info(f\"Successfully removed non-valid emails. Number of rows changed {changed_rows_email},in stores table,column EmailAddress.\")\n",
    "except Exception as e:\n",
    "    logging.warning(\"error occured: error removing non-valid emails\", exc_info=True)\n",
    "print(\"Number of rows changed:\", changed_rows_email)\n",
    "\n",
    "df_stores['EmailAddress'] = df_stores['EmailAddress'].apply(clean_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01504b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a phone number is in the correct format\n",
    "def is_valid_phone(phone):\n",
    "    pattern = r'^0\\d{9}$'  # Phone number should start with 0 and have exactly 10 digits\n",
    "    return re.match(pattern, phone) is not None\n",
    "\n",
    "# Function to clean the phone numbers\n",
    "def clean_phone(phone):\n",
    "    if is_valid_phone(phone):\n",
    "        return phone\n",
    "    else:\n",
    "        return None\n",
    "try:    \n",
    "    original_TelephoneNumber = df_stores['TelephoneNumber']\n",
    "    cleaned_TelephoneNumber = original_TelephoneNumber.apply(clean_phone)\n",
    "    # Count the number of rows that changed\n",
    "    changed_rows_TelephoneNumber = (original_TelephoneNumber != cleaned_TelephoneNumber).sum()\n",
    "    logging.info(f\"Successfully removed non-valid contact numbers. Number of rows changed {changed_rows_TelephoneNumber},in stores table,column ContactNumber.\")\n",
    "except Exception as e:\n",
    "    logging.warning(\"error occured: error removing non-valid contact numbers\", exc_info=True)\n",
    "print(\"Number of rows changed:\", changed_rows_TelephoneNumber)\n",
    "    \n",
    "df_stores['TelephoneNumber'] = df_stores['TelephoneNumber'].apply(clean_phone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163dc6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#formating startime and endtime to time data type\n",
    "try:\n",
    "    day_part_time = ('StartTime','EndTime')\n",
    "\n",
    "    for start_end_time in day_part_time:\n",
    "        df_day_part[start_end_time] = df_day_part[start_end_time].astype(str)\n",
    "        # used a Zfill function to fill the column with zeros to be 6 characters long\n",
    "        df_day_part[start_end_time] = df_day_part[start_end_time].apply(lambda x: x.zfill(6))\n",
    "        # Split the string into hours, minutes, and seconds\n",
    "        df_day_part[start_end_time] = df_day_part[start_end_time].apply(lambda x: ':'.join([x[:2], x[2:4], x[4:]]))\n",
    "        # removes dates for the datetime format  \n",
    "        df_day_part[start_end_time] = pd.to_datetime(df_day_part[start_end_time], format='%H:%M:%S').dt.time\n",
    "    logging.info(\"Successfully formated StartTime and EndTime to time data type in DayPart table\")\n",
    "except Exception as e:\n",
    "    logging.warning(\"error occured: error formating StartTime and EndTime to time data type in DayPart table \", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465837c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:    \n",
    "    # Convert 'ContactNumber' column to string\n",
    "    # Replace 'None' with NaN (missing values)\n",
    "    df_owner_operator['ContactNumber'] = df_owner_operator['ContactNumber'].replace('None', np.nan)\n",
    "    # Convert 'ContactNumber' column to string\n",
    "    df_owner_operator['ContactNumber'] = df_owner_operator['ContactNumber'].astype(str)\n",
    "    # Remove any decimal points from floating-point values and pad with leading zeros\n",
    "    df_owner_operator['ContactNumber'] = df_owner_operator['ContactNumber'].str.split('.').str[0].str.zfill(10)\n",
    "\n",
    "    df_owner_operator['ContactNumber'] = df_owner_operator['ContactNumber'].replace('None', np.nan)\n",
    "    # Convert 'ContactNumber' column to string\n",
    "    # Remove leading '0' characters before 'None'\n",
    "    df_owner_operator['ContactNumber'] = df_owner_operator['ContactNumber'].str.replace(r'^0+(?=None)', '', regex=True)\n",
    "    df_owner_operator['ContactNumber'] = df_owner_operator['ContactNumber'].astype(str)\n",
    "    logging.info(\" Successfully converted ContactNumber column to a string in OwnerOperator table \")\n",
    "except Exception as e:\n",
    "    logging.warning(\"error occured: error converting ContactNumber column to a string in OwnerOperator table \", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4348b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change ints to boolean in owner_operator and franchisee tables \n",
    "try:\n",
    "    df_tbl_names = (df_owner_operator,df_franchisee)\n",
    "\n",
    "    for tbl in df_tbl_names:\n",
    "        tbl['Active'] = tbl['Active'].astype(str)\n",
    "        tbl['Active'] = tbl['Active'] == '1'\n",
    "    logging.info(\"Successfully converted integers into boolean type in Active column in OwnerOperator and franchisee tables.\")\n",
    "except Exception as e:\n",
    "    logging.warning(\"error occured: error converting integers into boolean type in Active column in OwnerOperator and franchisee tables. \", exc_info=True)\n",
    "# change ints to boolean in stores and daily_sales_products table\n",
    "try:\n",
    "    colms_names = ('Cafe','GeneratorID','DriveThru','Deliveries','OpenStatusID','PlayPlace','Wifi','DessertKiosk')\n",
    "\n",
    "    for col in colms_names:\n",
    "        df_stores[col] = df_stores[col].astype(str)\n",
    "        df_stores[col] = df_stores[col] == '1'\n",
    "        df_daily_sales_products[col] = df_daily_sales_products[col].astype(str)\n",
    "        df_daily_sales_products[col] = df_daily_sales_products[col] == '1'\n",
    "        logging.info(\"Successfully converted integers into boolean type in stores and DailySalesProducts\")\n",
    "except Exception as e:\n",
    "    logging.warning(\"error occured: error converting integers into boolean type in stores and DailySalesProducts. \", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7debe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:  \n",
    "    # setting the time zone to South African time \n",
    "    sa_tz = pytz.timezone('Africa/Johannesburg')\n",
    "    start_time = datetime.now(sa_tz)\n",
    "    print(f'start time :{start_time}')\n",
    "    new_date = [start_time]  # New data to be added\n",
    "    start_date = {'start_load_date':new_date}  # Name of the existing column\n",
    "    df_start_date = pd.DataFrame(start_date)\n",
    "    df_start_date.to_sql('dw_batch', engine_staging, if_exists='append', index=False)\n",
    "    logging.info(\"start time successfully loaded into dw_batch table\")\n",
    "    print(\"start time successfully loaded into dw_batch table\")\n",
    "except Exception as e:\n",
    "    logging.warning(\"error occured: start time not loaded in the dw_batch table\", exc_info=True)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede5fc8b-9076-4277-8aae-071015fbe661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary with table names and dataframes\n",
    "dict_table_names = {'dim_country':df_country,\n",
    "                    'dim_province':df_province,\n",
    "                    'dim_city':df_city,\n",
    "                    'dim_order_type':df_order_type,\n",
    "                    'dim_sales_type':df_sales_type,\n",
    "                    'dim_trading_hours':df_trading_hours,\n",
    "                    'dim_volumn_band':df_volumn_band,\n",
    "                    'dim_day_date':df_day_date,\n",
    "                    'dim_day_part':df_day_part,\n",
    "                    'dim_location':df_location,\n",
    "                    'dim_owner_operator':df_owner_operator,\n",
    "                    'dim_franchisee':df_franchisee,\n",
    "                    'dim_product_category':df_product_category,\n",
    "                    'dim_product_group_level1':df_product_group_level1,\n",
    "                    'dim_product_group_level2':df_product_group_level2,\n",
    "                    'dim_product_group_level3':df_product_group_level3,\n",
    "                    'dim_product_group_level4':df_product_group_level4,\n",
    "                    'dim_stores':df_stores,\n",
    "                    'fact_daily_sales':df_daily_sales_products\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627f826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file storing successfully loaded tables exists\n",
    "if os.path.exists(\"successfully_loaded_tables.txt\"):\n",
    "    with open(\"successfully_loaded_tables.txt\", \"r\") as file:\n",
    "        successfully_loaded_tables = file.read().splitlines()\n",
    "else:\n",
    "    successfully_loaded_tables = []\n",
    "\n",
    "transaction = engine_DW.begin()\n",
    "\n",
    "for table_name, df in dict_table_names.items():\n",
    "    if table_name in successfully_loaded_tables:\n",
    "        print(f\"Table '{table_name}' has already been successfully loaded. Skipping...\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        df.to_sql(table_name, engine_DW, if_exists='append', index=False)\n",
    "        print(f\"Table '{table_name}' successfully loaded.\")\n",
    "        successfully_loaded_tables.append(table_name)\n",
    "        logging.info(f\"Table '{table_name}' successfully loaded.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading table '{table_name}': {e}\")\n",
    "        logging.warning(f\"error occured: Error loading table '{table_name}': {e}\")\n",
    "# Write the list of successfully loaded tables to the file\n",
    "with open(\"successfully_loaded_tables.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join(successfully_loaded_tables))\n",
    "\n",
    "try:\n",
    "    if len(successfully_loaded_tables) == len(dict_table_names):\n",
    "        os.remove(\"successfully_loaded_tables.txt\")\n",
    "        print(\"All tables have been successfully loaded. The file has been deleted.\")\n",
    "        logging.info(\"All tables have been successfully loaded. The file has been deleted\")\n",
    "except Exception as e:\n",
    "    logging.warning(\"error occured: Some tables have not been loaded. The file has not been deleted\", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d1fd91-dcf6-4e05-bd0b-fac67b910314",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tz = pytz.timezone('Africa/Johannesburg')\n",
    "end_time = datetime.now(sa_tz)\n",
    "logging.info(f'Successfully finished loading at end_time:{end_time}')\n",
    "print(f'end_time:{end_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70bd665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the max dwbID from the staging area\n",
    "sql_line = 'SELECT \"dwbID\" FROM dw_batch order by \"dwbID\" desc limit 1'\n",
    "df_dw_batch = pd.read_sql_query(sql_line, engine_staging)\n",
    "dw_batch_id =df_dw_batch['dwbID'].squeeze()\n",
    "dw_batch_id_int = int(dw_batch_id)\n",
    "print(dw_batch_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbee543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SQL query to select the latest record from staging_batch\n",
    "sql_line = 'SELECT * FROM dw_batch ORDER BY \"dwbID\" DESC LIMIT 1'\n",
    "\n",
    "# Begin a transaction\n",
    "transaction = engine_staging.begin()\n",
    "\n",
    "try:\n",
    "    # Read the latest record into a DataFrame\n",
    "    df_dw_batch = pd.read_sql_query(sql_line, engine_staging)\n",
    "\n",
    "    # Check if the latest record matches the dw_batch_id\n",
    "    print(\"Latest dw_batch_id from database:\", df_dw_batch[\"dwbID\"].iloc[0])\n",
    "    print(end_time)\n",
    "    if df_dw_batch[\"dwbID\"].iloc[0] == dw_batch_id:\n",
    "        connection = engine_staging.connect()\n",
    "        # Update the end_load_date column with the provided end_time\n",
    "        update_sql = text(f'UPDATE \"dw_batch\" SET \"end_load_date\" = :end_time WHERE \"dwbID\" = :dw_batch_id')\n",
    "        # Execute the SQL UPDATE statement with parameters\n",
    "        connection.execute(update_sql, {'end_time': end_time, 'dw_batch_id': dw_batch_id_int})\n",
    "        connection.commit()\n",
    "        connection.close()\n",
    "        print(\"end_load_date updated successfully.\")\n",
    "        logging.info(\"end_load_date updated successfully.\")\n",
    "    else:\n",
    "        print(\"dw_batch_id does not match the latest record in the database.\")\n",
    "except SQLAlchemyError as e:\n",
    "    # If there is an error, rollback the transaction\n",
    "    transaction.rollback()\n",
    "    print(f\"Error occurred: {e}\")\n",
    "    logging.warning(f\"Error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831640ce-73b3-49df-88f2-3d55663ac75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of table names for staging area \n",
    "table_list = ['city',\n",
    "               'country',\n",
    "               'province',\n",
    "               'day_part',\n",
    "               'day_date',\n",
    "               'franchisee',\n",
    "               'product_category',\n",
    "               'stores',\n",
    "               'product_group_level1',\n",
    "               'product_group_level2',\n",
    "               'product_group_level3',\n",
    "               'product_group_level4',\n",
    "               'sales_type',\n",
    "               'trading_hours',\n",
    "               'volumn_band',\n",
    "               'owner_operator',\n",
    "               'order_type',\n",
    "               'daily_sales_products']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c3207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data into the data warehouse using the list\n",
    "for table_name in table_list:\n",
    "    try:\n",
    "        connection = engine_staging.connect()\n",
    "        # Update the end_load_date column with the provided end_time\n",
    "        update_sql = text(f'UPDATE \"{table_name}\" SET \"dwbID\" = :dw_batch_id_int WHERE \"dwbID\" IS NULL')       \n",
    "        # Execute the SQL UPDATE statement\n",
    "        connection.execute(update_sql, {'dw_batch_id_int': dw_batch_id_int})\n",
    "        connection.commit()\n",
    "        connection.close()\n",
    "        print(\"end_load_date updated successfully for table:\", table_name)\n",
    "        logging.info(f\"end_load_date updated successfully for table: {table_name}\" )\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading table '{table_name}': {e}\")\n",
    "        logging.warning(f\"Error loading end_load_date in table '{table_name}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c0e19d-e19d-455b-b978-ef55bc15243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of table names for data warehouse \n",
    "table_list2 = ['dim_city',\n",
    "               'dim_country',\n",
    "               'dim_province',\n",
    "               'dim_location',\n",
    "               'dim_day_part',\n",
    "               'dim_franchisee',\n",
    "               'dim_product_category',\n",
    "               'dim_stores',\n",
    "               'dim_product_group_level1',\n",
    "               'dim_product_group_level2',\n",
    "               'dim_product_group_level3',\n",
    "               'dim_product_group_level4',\n",
    "               'dim_sales_type',\n",
    "               'dim_trading_hours',\n",
    "               'dim_volumn_band',\n",
    "               'dim_owner_operator',\n",
    "               'dim_order_type',\n",
    "               'fact_daily_sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e3dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data into the data warehouse using the list\n",
    "for table_name in table_list2:\n",
    "    try:\n",
    "        connection = engine_DW.connect()\n",
    "        # Update the end_load_date column with the provided end_time\n",
    "        update_sql_is_current = text(f'UPDATE \"{table_name}\" SET \"IsCurrent\" = True WHERE \"IsCurrent\" IS NULL')       \n",
    "        # Execute the SQL UPDATE statement with parameters\n",
    "        connection.execute(update_sql_is_current)\n",
    "        connection.commit()\n",
    "        connection.close()\n",
    "        print(\"IsCurrent updated successfully for table:\", table_name)\n",
    "        logging.info(f\"IsCurrent updated successfully for table:{table_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading table '{table_name}': {e}\")\n",
    "        logging.warning(f\"Error loading isCurrent in table '{table_name}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e65f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of table names for data warehouse \n",
    "table_list3 = ['dim_city',\n",
    "               'dim_country',\n",
    "               'dim_province',\n",
    "               'dim_location',\n",
    "               'dim_day_part',\n",
    "               'dim_franchisee',\n",
    "               'dim_product_category',\n",
    "               'dim_stores',\n",
    "               'dim_product_group_level1',\n",
    "               'dim_product_group_level2',\n",
    "               'dim_product_group_level3',\n",
    "               'dim_product_group_level4',\n",
    "               'dim_sales_type',\n",
    "               'dim_trading_hours',\n",
    "               'dim_volumn_band',\n",
    "               'dim_owner_operator',\n",
    "               'dim_order_type',\n",
    "               'fact_daily_sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadf7504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data into the data warehouse using the list\n",
    "connection = engine_DW.connect()\n",
    "\n",
    "for effective_time_tables in table_list3:\n",
    "    try:\n",
    "        update_sql = text(f'UPDATE \"{effective_time_tables}\" SET \"Effective\" = :end_time WHERE \"Effective\" IS NULL')\n",
    "        connection.execute(update_sql, {'end_time': end_time})\n",
    "        connection.commit()\n",
    "        print(\"Effective updated successfully for table:\", effective_time_tables)\n",
    "        logging.info(f\"Effective updated successfully for table:{effective_time_tables}\")\n",
    "    except Exception as e: print(e)\n",
    "    logging.warning(f\"Error loading Effective in table {table_name}\")\n",
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
