{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a0e03b-8b03-403d-a6fe-5834e82c0825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n",
    "import psycopg2\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73604fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log file name\n",
    "log_file = 'etl_to_staging_area_logs.txt'\n",
    "\n",
    "# Checking if the log file exists\n",
    "# if os.path.exists(log_file):\n",
    "#     # If the file exists, it will be deleted \n",
    "#     os.remove(log_file)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=log_file,\n",
    "    level=logging.INFO,\n",
    "    format='execution time: %(asctime)s - Details: %(message)s'\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bedb48-2bcb-4a0c-8e81-873af226653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    countryTB = r\"C:\\Users\\kmakh\\Downloads\\McD_Data\\data\\Country.csv\"\n",
    "    cityTB = r\"C:\\Users\\kmakh\\Downloads\\McD_Data\\data\\City.csv\"\n",
    "    provinceTB = r\"C:\\Users\\kmakh\\Downloads\\McD_Data\\data\\Province.csv\"\n",
    "    franchiseeTB = r\"C:\\Users\\kmakh\\Downloads\\McD_Data\\data\\Franchisee.csv\"\n",
    "    dayDateTB = r\"C:\\Users\\kmakh\\Downloads\\McD_Data\\data\\DayDate.csv\"\n",
    "    dayPartTB = r\"C:\\Users\\kmakh\\Downloads\\McD_Data\\data\\DayPart.csv\"\n",
    "    dailySalesProductTB = r\"C:\\Users\\kmakh\\Downloads\\McD_Data\\data\\DailySalesProducts.csv\"\n",
    "    orderTypeTB = r\"C:\\Users\\kmakh\\Downloads\\McD_Data\\data\\OrderType.csv\"\n",
    "    ownerOperatorTB = r\"C:\\Users\\kmakh\\Downloads\\McD_Data\\data\\OwnerOperator.csv\"\n",
    "    productCategoryTB = r\"C:\\Users\\kmakh\\Downloads\\McD_Data\\data\\ProductCategory.csv\"\n",
    "    productGroupLevel1TB = r\"C:\\Users\\kmakh\\Downloads\\McD_Data\\data\\ProductGroupLevel1.csv\"\n",
    "    productGroupLevel2TB = r\"C:\\Users\\kmakh\\Downloads\\McD_Data\\data\\ProductGroupLevel2.csv\"\n",
    "    productGroupLevel3TB = r\"C:\\Users\\kmakh\\Downloads\\McD_Data\\data\\ProductGroupLevel3.csv\"\n",
    "    productGroupLevel4TB = r\"C:\\Users\\kmakh\\Downloads\\McD_Data\\data\\ProductGroupLevel4.csv\"\n",
    "    salesTypeTB = r\"C:\\Users\\kmakh\\Downloads\\McD_Data\\data\\SalesType.csv\"\n",
    "    storesTB = r\"C:\\Users\\kmakh\\Downloads\\McD_Data\\data\\Stores.csv\"\n",
    "    tradingHoursTB = r\"C:\\Users\\kmakh\\Downloads\\McD_Data\\data\\TradingHours.csv\"\n",
    "    volumnBandTB = r\"C:\\Users\\kmakh\\Downloads\\McD_Data\\data\\VolumnBand.csv\"\n",
    "    logging.info('Extracting all the csv files was successful')\n",
    "except Exception as e:\n",
    "    logging.warning(\"An exception occurred:\", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed16ddda-a488-46dc-ac1f-708fdeccfee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables for connection parameters for staging area\n",
    "username = 'postgres'\n",
    "password = 'makhubela'\n",
    "host = 'localhost'\n",
    "port = '5432'\n",
    "database = 'DW_staging_area'\n",
    "\n",
    "# Construct the connection string using variables\n",
    "connection_string_staging = f'postgresql://{username}:{password}@{host}:{port}/{database}'\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine_staging = create_engine(connection_string_staging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54aa192-d4e4-41e4-9883-055f85fa600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data from the csv file to the data frames\n",
    "\n",
    "try:\n",
    "    df_country = pd.read_csv(countryTB)\n",
    "    df_city =pd.read_csv(cityTB)\n",
    "    df_province =pd.read_csv(provinceTB)\n",
    "    df_franchisee =pd.read_csv(franchiseeTB)\n",
    "    df_dayDate=pd.read_csv(dayDateTB)\n",
    "    df_dayPart =pd.read_csv(dayPartTB)\n",
    "    df_dailySalesProduct =pd.read_csv(dailySalesProductTB)\n",
    "    df_productCategory =pd.read_csv(productCategoryTB)\n",
    "    df_productGroupLevel1 =pd.read_csv(productGroupLevel1TB)\n",
    "    df_productGroupLevel2 =pd.read_csv(productGroupLevel2TB)\n",
    "    df_productGroupLevel3 =pd.read_csv(productGroupLevel3TB)\n",
    "    df_productGroupLevel4 =pd.read_csv(productGroupLevel4TB)\n",
    "    df_salesType =pd.read_csv(salesTypeTB)\n",
    "    df_stores =pd.read_csv(storesTB)\n",
    "    df_tradingHours =pd.read_csv(tradingHoursTB)\n",
    "    df_volumnBand =pd.read_csv(volumnBandTB)\n",
    "    df_ownerOperator =pd.read_csv(ownerOperatorTB)\n",
    "    df_orderType = pd.read_csv(orderTypeTB)\n",
    "    logging.info(\"18 tables from csv's have been converted to dataframes successfully!!\")\n",
    "except Exception as e:\n",
    "    logging.warning(\"error occured: error loading tables as dataframes\", exc_info=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c80a9c0-2a06-4f97-aa93-f2c8744bcb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataFrames dict\n",
    "\n",
    "dataframes = {\n",
    "    'city': df_city,\n",
    "    'country': df_country,\n",
    "    'province':df_province,\n",
    "    'day_part':df_dayPart,\n",
    "    'day_date':df_dayDate,\n",
    "    'franchisee':df_franchisee,\n",
    "    'product_category':df_productCategory,\n",
    "    'stores':df_stores,\n",
    "    'product_group_level1':df_productGroupLevel1,\n",
    "    'product_group_level2':df_productGroupLevel2,\n",
    "    'product_group_level3':df_productGroupLevel3,\n",
    "    'product_group_level4':df_productGroupLevel4,\n",
    "    'sales_type':df_salesType,\n",
    "    'trading_hours':df_tradingHours,\n",
    "    'volumn_band':df_volumnBand,\n",
    "    'owner_operator' : df_ownerOperator,\n",
    "    'order_type' : df_orderType,\n",
    "    'daily_sales_products':df_dailySalesProduct\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d656839-801e-4e54-a846-5d6690c905ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:    \n",
    "    sa_tz = pytz.timezone('Africa/Johannesburg')\n",
    "    start_time = datetime.now(sa_tz)\n",
    "    print(f'start time :{start_time}')\n",
    "    new_date = [start_time]  # New data to be added\n",
    "    start_date = {'start_load_date':new_date}  # Name of the existing column\n",
    "    #df[existing_column] = df[existing_column].append(pd.Series(new_data), ignore_index=True)\n",
    "    df_start_date = pd.DataFrame(start_date)\n",
    "    # Step 3: Write the updated DataFrame back to the database\n",
    "    df_start_date.to_sql('staging_batch', engine_staging, if_exists='append', index=False)\n",
    "    logging.info(\"start time successfully loaded into staging_batch table\")\n",
    "    print(\"start time successfully loaded into staging_batch table\")\n",
    "except Exception as e:\n",
    "    logging.warning(\"error occured: start time not loaded in the staging_batch table\", exc_info=True)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0c78b1-1925-41f7-8c9c-fb62e478c68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sql_line = 'SELECT \"sbID\" FROM staging_batch order by \"sbID\" desc limit 1'\n",
    "    df_staging_batch = pd.read_sql_query(sql_line, engine_staging)\n",
    "    staging_batch_id =df_staging_batch['sbID'].squeeze()\n",
    "    logging.info('batch id successfully loaded')\n",
    "    print(staging_batch_id)\n",
    "except Exception as e:\n",
    "    logging.warning(\"error occured: staging area batch id not assigned to staging_batch table\", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663457be-8f36-481b-b95c-afb5fcef5e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "for table_name, df in dataframes.items(): \n",
    "    try:\n",
    "        df['sbID'] = staging_batch_id\n",
    "        df.to_sql(table_name, engine_staging, if_exists='append', index=False)\n",
    "        logging.info(f\"Table '{table_name}' successfully loaded consists of {df.shape[0]} rows.\")\n",
    "        print(f\"Table '{table_name}' successfully loaded {df.shape[0]} .\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading table '{table_name} ': {e}\")\n",
    "        logging.warning(f\"error occured: Error loading table '{table_name}': {e}\", exc_info=True)\n",
    "end_time = datetime.now(sa_tz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f80100-8b70-4559-8ba0-683dfafe430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end_time_str = end_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "staging_batch_id_int = int(staging_batch_id)\n",
    "# Define the SQL query to select the latest record from staging_batch\n",
    "sql_line = 'SELECT * FROM staging_batch ORDER BY \"sbID\" DESC LIMIT 1'\n",
    " \n",
    "# Read the latest record into a DataFrame\n",
    "df_staging_batch = pd.read_sql_query(sql_line, engine_staging)\n",
    " \n",
    "# Check if the latest record matches the staging_batch_id\n",
    "print(\"Latest staging_batch_id from database:\", df_staging_batch[\"sbID\"].iloc[0])\n",
    "print(end_time)\n",
    "if df_staging_batch[\"sbID\"].iloc[0] == staging_batch_id:\n",
    "    connection = engine_staging.connect()\n",
    "    # Update the end_load_date column with the provided end_time\n",
    "    update_sql = text( f'UPDATE \"staging_batch\" SET \"end_load_date\" = :end_time WHERE \"sbID\" = :staging_batch_id')         \n",
    "# Execute the SQL UPDATE statement with parameters\n",
    "   \n",
    "    connection.execute(update_sql, {'end_time': end_time, 'staging_batch_id': staging_batch_id_int})\n",
    "    connection.commit()\n",
    "    logging.info('end_load_date updated successfully.')\n",
    "    print(\"end_load_date updated successfully.\")\n",
    "else:\n",
    "    print(\"staging_batch_id does not match the latest record in the database.\")\n",
    "    logging.info('staging_batch_id does not match the latest record in the database.')\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3eee5e-c3ba-4377-b067-a9161e76af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'end time :{end_time}')\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total time taken: {total_time}\")\n",
    "logging.info(f'total time taken to load the staging area = {total_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbbcc06-9618-4a12-93c5-b12c0542d151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
